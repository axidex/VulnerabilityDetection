{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'median')\\n\", 'stop_id,\\n', \"'python_precompiled'\\n\", 'conn.request(\"HEAD\",\\n', 'self.backend.groupmeta_collection\\n', 'test_inheritance25(self)\\n', \"'/mnt/pyami'\\n\", '**{\"list_namespaced_deployment.return_value.to_dict.return_value\"\\n', 'g._auto_cast_variable_read_dtype)\\n', 'fd1\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('w2v/vocab') as f:\n",
    "    vocab = f.readlines()\n",
    "print(vocab[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)/3\n",
    "vocab = vocab[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {word:idx for idx,word in enumerate(vocab)} # give unique identifier to each unique token\n",
    "id2word = {idx:word for idx,word in enumerate(vocab)}\n",
    "window = 2        # context window size\n",
    "embeddings = 100  # number of embeddings to be used for representation\n",
    "epochs = 100     # number of training iterations\n",
    "lr = 0.001       # learning rate for CBOW \n",
    "vocab_size = len(vocab)  # size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for pytorch; context, target word tensors\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 38318.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def context_vector(tokens:list):\n",
    "    # list of values for each token\n",
    "    val_context = [word2id[word] for word in tokens] \n",
    "    return val_context\n",
    "    \n",
    "    \n",
    "context_pairs = []\n",
    "\n",
    "# loop through all possible cases \n",
    "for i in tqdm(range(window,len(vocab) - window)):\n",
    "    \n",
    "    context = []\n",
    "    \n",
    "    # words to the left\n",
    "    for j in range(-window,0):\n",
    "        context.append(vocab[i+j])\n",
    "    \n",
    "    # words to the right\n",
    "    for j in range(1,window+1):\n",
    "        context.append(vocab[i+j])\n",
    "        \n",
    "    context_pairs.append((context,vocab[i]))\n",
    "    \n",
    "# show all context pairs in document\n",
    "# print('context, target pairs\\n')\n",
    "# for context in context_pairs:\n",
    "#     print(context)\n",
    "    \n",
    "# sample tensor conversion\n",
    "print('\\nfor pytorch; context, target word tensors\\n')\n",
    "for context,target in tqdm(context_pairs):\n",
    "    X = torch.tensor(context_vector(context))\n",
    "    y = torch.tensor(word2id[target])\n",
    "    # print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\StepW\\anaconda3\\envs\\cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "torch.cuda.empty_cache() \n",
    "class CBOW(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_dim):\n",
    "        super(CBOW,self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim,vocab_size)\n",
    "        self.active = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = sum(self.embedding(x)).view(1,-1)\n",
    "        x = self.linear(x)\n",
    "        x = self.active(x)\n",
    "        return x\n",
    "    \n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = CBOW(vocab_size,embeddings)\n",
    "model.to(dev)\n",
    "criterion = nn.NLLLoss()\n",
    "optimiser = Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "[([\"'median')\\n\", 'stop_id,\\n', 'conn.request(\"HEAD\",\\n', 'self.backend.groupmeta_collection\\n'], \"'python_precompiled'\\n\"), (['stop_id,\\n', \"'python_precompiled'\\n\", 'self.backend.groupmeta_collection\\n', 'test_inheritance25(self)\\n'], 'conn.request(\"HEAD\",\\n'), ([\"'python_precompiled'\\n\", 'conn.request(\"HEAD\",\\n', 'test_inheritance25(self)\\n', \"'/mnt/pyami'\\n\"], 'self.backend.groupmeta_collection\\n'), (['conn.request(\"HEAD\",\\n', 'self.backend.groupmeta_collection\\n', \"'/mnt/pyami'\\n\", '**{\"list_namespaced_deployment.return_value.to_dict.return_value\"\\n'], 'test_inheritance25(self)\\n'), (['self.backend.groupmeta_collection\\n', 'test_inheritance25(self)\\n', '**{\"list_namespaced_deployment.return_value.to_dict.return_value\"\\n', 'g._auto_cast_variable_read_dtype)\\n'], \"'/mnt/pyami'\\n\"), (['test_inheritance25(self)\\n', \"'/mnt/pyami'\\n\", 'g._auto_cast_variable_read_dtype)\\n', 'fd1\\n'], '**{\"list_namespaced_deployment.return_value.to_dict.return_value\"\\n'), ([\"'/mnt/pyami'\\n\", '**{\"list_namespaced_deployment.return_value.to_dict.return_value\"\\n', 'fd1\\n', '2003-2005\\n'], 'g._auto_cast_variable_read_dtype)\\n'), (['**{\"list_namespaced_deployment.return_value.to_dict.return_value\"\\n', 'g._auto_cast_variable_read_dtype)\\n', '2003-2005\\n', 'self.match(117)\\n'], 'fd1\\n'), (['g._auto_cast_variable_read_dtype)\\n', 'fd1\\n', 'self.match(117)\\n', 'infos[0].platforms\\n'], '2003-2005\\n'), (['fd1\\n', '2003-2005\\n', 'infos[0].platforms\\n', '`~pandas.DataFrame`\\n'], 'self.match(117)\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(len(context_pairs)/3)\n",
    "print(context_pairs[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.640030860900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "lst_loss = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    loss = 0.0\n",
    "    for context,target in context_pairs:\n",
    "        \n",
    "        X = torch.tensor(context_vector(context)).to(dev)\n",
    "        y = torch.tensor([word2id[target]]).to(dev)        \n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss += criterion(y_pred,y)\n",
    "        \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    lst_loss.append(float(loss.cpu().detach().numpy()))\n",
    "        \n",
    "print(lst_loss[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
